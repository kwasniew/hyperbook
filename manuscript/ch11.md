# Chapter 11: Integration testing

## Comparing integration test options

If you find yourself struggling with excessive mocking and hard to maintain tests consider integration testing your application. 
Some JS developers find their **integration tests** give them more leverage than unit tests.
Therefore they subvert a traditional [test pyramid](https://martinfowler.com/bliki/TestPyramid.html) and write more [integration tests](https://twitter.com/swyx/status/1261202288476971008) than unit tests.


One popular option for integration testing your app is DOM emulation with [jsdom](https://github.com/jsdom/jsdom) and polyfills/test doubles for various browser APIs such as fetch, localStorage, or EventSource.
This approach allows you to write Node.js tests for your frontend code without spinning a browser. 
We've spent too much time trying to match the browser environment in this setup, so we're not sure if it's worth the effort. But, it has its advantages, so your mileage may vary. Also, with `jsdom`, you're not integration testing against a real browser. 

`jsdom` based setup tradeoffs:
* (+) easy to run from CLI without extra tooling
* (+) faster tests in CI server than spinning-up browser tests
* (-) slow startup time for the first test which makes subsecond testing impossible
* (-) can't find browser discrepancies

Another option is to run your tests in a real browser.
With this approach, all APIs just work, and you can inspect a failing test with your DevTools. 

Browser-based setup tradeoffs:
* (+) testing a real browser
* (+) easy to inspect the environment after a failing tests
* (+) all browser APIs just work
* (+) with an open browser, the first test starts instantly  
* (-) cleaning the environment between tests is cumbersome
* (-) requires complex tooling to run in the CI server
* (-) with many tests it's slower than `jsdom` setup because of the rendering overhead

We're going to focus on using a real browser for integration testing in this book.

## Testing in a browser

Mocha tests can run in both Node.js and a browser. Not all test runners have this capability.

Create **test/index.html** with the following boilerplate:
```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <title>Mocha Tests</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="https://unpkg.com/mocha/mocha.css" />
</head>
<body>
<div id="mocha">
    <div id="app"></div>
</div>

<script src="https://unpkg.com/mocha@7.1.2/mocha.js"></script>
<script src="https://unpkg.com/chai@4.2.0/chai.js"></script>
<script src="https://unpkg.com/@testing-library/dom@7.5.6/dist/@testing-library/dom.umd.js"></script>

<script class="mocha-init">
    mocha.setup('bdd');
</script>
<script type="module" src="App.test.js"></script>
<script type="module" class="mocha-exec">
    mocha.run();
</script>
</body>
</html>
```
This setup loads three scripts.
* mocha - browser-based test runner
* [chai](https://www.chaijs.com/) - assertion library. Browsers don't provide built-in assertion libraries similar to Node `assert`
* [@testing-library/dom](https://testing-library.com/) - a helpful utility library you'll use for asynchronous rendering testing  

We load the scripts from unpkg.com. In real-world setup, you'd load local versions. Also, you can load all scripts other than mocha as ESM imports.

Your app will mount to `<div id="app"></div>`.

Write a test in **test/App.test.js**:
```js
const { assert } = chai;
const { getAllByTestId, waitFor } = TestingLibraryDom;
import { start } from "../src/App.js";

const container = () => document.getElementById("app");

describe("App", () => {
  beforeEach(function () {
    container().innerHTML = "";
  });

  it("Load initial posts", async () => {
    start();
    await waitFor(() => {
      assert.strictEqual(getAllByTestId(container(), "item").length, 10);
    });
  });
});

```
The code cleans up the app container before every test. It's essential to start each test with a clean slate.
Always prefer `beforeEach` over `afterEach` for cleanup as you may need to inspect a failing test every now and then.
`afterEach` would erase useful debugging information.

Inside a test, start a new instance of the app. You'll build the `start` function in the next step. 
Then wait for the ten items to show up.
 
`getAllByTestId(container(), "item")` is a utility querying for `data-testid="item"` inside a `container()`.

`waitFor` is a utility that waits until:
* the assertion doesn't throw any errors
* `waitFor` times out 
* mocha times out

Change **src/App.js**:
```js
import { app } from "./web_modules/hyperapp.js";
import { init, view, subscriptions } from "./Posts.js";

export const start = () =>
  app({
    init,
    view,
    subscriptions,
    node: document.getElementById("app"),
  });
```
You defer the app initialization so that it can be started anew in each test.
Now the app is broken. Let's fix it before you go back to the tests.

Add **src/Start.js**:
```js
import { start } from "./App.js";

start();
```
Refer to this file from **src/index.html**:
```html
<script type="module" src="Start.js"></script>
```

Check if the app is working.
Going back to tests. Add the test data attribute to the `listItem` view fragment in **src/Posts.js**:
```js
const listItem = (post) => html`
  <li key=${post.id} data-key=${post.id} data-testid="item">
    ...
  </li>
`;
```
You'll use data attributes such as `data-testid` to make the tests independent of the DOM structure. It will keep your test stable even if you have to rewrite particular tags e. g. because of a new design.

Before you start integration testing, make sure that backend API is running.
Go to: https://hyperapp-api.herokuapp.com/api/post. Heroku hosting put's the app to sleep if it hasn't been used recently. Opening the URL should wake it up.

Start a server from the root directory by running:
`http-server .`

Open http://localhost:8080/test/ in your browser. The test should be green.

![Figure: Mocha browser test output](images/mocha-browser.png)


## Testing more advanced browser scenario

Add a test for the post submission and waiting for the SSE notification:
```js
// new imports
const {
  getAllByTestId,
  waitFor,
  findByTestId,
  findByText,
  fireEvent,
} = TestingLibraryDom;

const randomMessage = () => `new message ${new Date().toJSON()}`;

const sendMessage = async (newMessage) => {
  const input = await findByTestId(container(), "post-input");
  input.value = newMessage;
  fireEvent.input(input);

  const button = await findByText(container(), "add-post");
  button.click();
};

const waitForMessage = async (message) => {
  await waitFor(() => {
    assert.strictEqual(
      getAllByTestId(container(), "item")[0].textContent,
      message
    );
  });
};

describe("App", () => {
  // ...

  it("Add a post as an anonymous user", async () => {
    start();
    const newMessage = randomMessage();

    await sendMessage(newMessage);

    await waitForMessage(`@anonymous ${newMessage}`);
  });
});
```
The test starts with a new app to make it independent of the other tests. 

Note: We're currently missing the ability to stop all subscriptions from the previous test in Hyperapp.

With the app started, the test is:
* creating a new random message
* sending the message to the server - @testing-library simplifies triggering DOM events such as typing a text. It also provides DOM queries that wait for DOM elements to appear in the UI.
* waiting for the message to show up at the top of the posts list

Put a test data attribute in **Posts.js**:
```js
    <input
      data-testid="post-input"
      type="text"
      oninput=${[UpdatePostText, targetValue]}
      value=${state.currentPostText}
      autofocus
    />
```

Check if both tests are green. They shouldn't. It's something you can fix now yourself.

## Exercise: Fix the test

Add `data-testid="add-post"` to the "Add Post" button.

<details>
    <summary id="integration_testing">Solution</summary>

```js
  <button onclick=${AddPost} data-testid="add-post">Add Post</button>
```

</details>

Check if both tests are green.

## Making integration tests faster and more predictable

Your integration test execution time and reliability are heavily dependent on the API response time and availability. 
There are at least two options to make your tests faster and more reliable:
1. record all HTTP traffic with a library like [PollyJS](https://netflix.github.io/pollyjs/#/). 
The first time you run the tests, it intercepts all network calls and saves them to localStorage or file system. 
Afterward, it can replay the traffic much faster than the original API. When the API changes, you make a new recording.
2. inject a fake implementation of all effects and subscriptions you want to replace. 
The trick is to move all effects and subscriptions to the entry point of your application.
In production you would need to start your app with real effects/subscriptions passed as arguments:
```js
import { start } from "./App.js";
import { Http } from "./web_modules/hyperapp-fx.js";
import { EventSourceListen } from "./lib/EventSource.js";
import { WithGuid } from "./lib/Guid.js";

start({ Http, EventSourceListen, WithGuid });
```
In your tests, you can provide a fake implementation of those effects/subscriptions. 
This technique requires minor code changes. Each module with effects needs to expose a function for injecting them.
It is essentially what some people call a **dependency injection**â€”a fancy name for passing arguments to functions.
 
We leave it to the reader to experiment with those techniques.